{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.path.abspath('')\n",
    "parent_dir = os.path.join(current_dir, '..', 'functions')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from duplicates_utils import normalize_id\n",
    "from mn_table_utils import create_mn_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP DUPLICATES ROWS FROM AUTHORS AND CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(654021, 2)\n",
      "(653783, 2)\n",
      "654021\n"
     ]
    }
   ],
   "source": [
    "authors_path = \"../../dataset/cleaned/authors_cleaned.csv\"\n",
    "df_authors = pd.read_csv(authors_path)\n",
    "\n",
    "print(df_authors.shape)\n",
    "\n",
    "df_authors,df_authors_map = normalize_id(df_authors, key_column = 'author_name', id_column = 'author_id')\n",
    "\n",
    "print(df_authors.shape)\n",
    "print(len(df_authors_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2775, 2)\n",
      "(2585, 2)\n",
      "2775\n"
     ]
    }
   ],
   "source": [
    "categories_path = \"../../dataset/cleaned/categories_cleaned.csv\"\n",
    "df_categories = pd.read_csv(categories_path)\n",
    "\n",
    "\n",
    "print(df_categories.shape)\n",
    "\n",
    "df_categories,df_categories_map = normalize_id(df_categories, key_column = 'category_name', id_column = 'category_id')\n",
    "\n",
    "print(df_categories.shape)\n",
    "print(len(df_categories_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE M:N TABLES FROM MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../dataset/cleaned/dataset_cleaned.csv\"\n",
    "df_dataset = pd.read_csv(dataset_path)\n",
    "df_dataset['id'] = range(1, len(df_dataset) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTHOR MN TABLE\n",
    "authors_mn_table = create_mn_table(df_dataset, id_column = 'id', key_column = 'authors')\n",
    "\n",
    "#add unknown id instead of missing id in mn table\n",
    "unknown_author_id = df_authors.loc[df_authors['author_name'] == 'Unknown', 'author_id'].iloc[0]\n",
    "authors_mn_table['authors_id'] = authors_mn_table['authors_id'].replace('', unknown_author_id)\n",
    "\n",
    "authors_mn_table['authors_id'] = authors_mn_table['authors_id'].str.strip()\n",
    "\n",
    "authors_mn_table['authors_id'] = (authors_mn_table['authors_id']\n",
    "    .map(df_authors_map).fillna(authors_mn_table['authors_id'])\n",
    "    .infer_objects(copy=False).astype('Int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  main_id categories_id\n",
      "1390099  1390100   328665              \n",
      "2459394  2459395   636324              \n",
      "2888189  2888190   774007              \n",
      "3893958  3893959  1054359              \n",
      "4040637  4040638  1103243              \n",
      "4050848  4050849  1106382              \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#CATHEGORIES MN TABLE\n",
    "categories_mn_table = create_mn_table(df_dataset, id_column = 'id', key_column = 'categories')\n",
    "\n",
    "print(categories_mn_table.loc[categories_mn_table['categories_id'] == ''])\n",
    "\n",
    "\n",
    "categories_mn_table['categories_id'] = (categories_mn_table['categories_id']\n",
    "    .replace('', np.nan)  \n",
    "    .map(df_categories_map)\n",
    "    .fillna(categories_mn_table['categories_id']))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_dataframes(df_dict, folder_path, file_format='csv'):\n",
    "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
    "        raise FileNotFoundError(f\"Dictionary '{folder_path}' does not exist.\")\n",
    "\n",
    "    for file_name, df in df_dict.items():\n",
    "        file_name = f\"{file_name}.{file_format}\" \n",
    "        file_path = os.path.join(folder_path, file_name)  \n",
    "\n",
    "        if file_format == 'csv':\n",
    "            df.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        elif file_format == 'xlsx':\n",
    "            df.to_excel(file_path, index=False, engine='openpyxl')\n",
    "        else:\n",
    "            raise ValueError(\"Unsuported file format.\")\n",
    "\n",
    "        print(f\"✅ File was save: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File was save: ../../dataset/to_sql\\final_dataset.csv\n",
      "✅ File was save: ../../dataset/to_sql\\final_categories.csv\n",
      "✅ File was save: ../../dataset/to_sql\\final_authors.csv\n",
      "✅ File was save: ../../dataset/to_sql\\mn_author.csv\n",
      "✅ File was save: ../../dataset/to_sql\\mn_categories.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = {'final_dataset': df_dataset, 'final_categories': df_categories,\n",
    "       'final_authors': df_authors,'mn_author': authors_mn_table,\n",
    "       'mn_categories': categories_mn_table}\n",
    "folder = \"../../dataset/to_sql\"\n",
    "\n",
    "save_dataframes(dfs, folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File was save\n"
     ]
    }
   ],
   "source": [
    "#formats.csv was not transfomed\n",
    "file_name = \"formats_cleaned.csv\"\n",
    "final_name = \"final_formats.csv\"\n",
    "folder_path = \"../../dataset/cleaned\"\n",
    "final_path = \"../../dataset/to_sql\"\n",
    "\n",
    "source_path = os.path.join(folder_path, file_name)\n",
    "destination_path = os.path.join(final_path, final_name)\n",
    "\n",
    "with open(source_path, \"rb\") as src, open(destination_path, \"wb\") as dst:\n",
    "    dst.write(src.read())\n",
    "\n",
    "print(f\"✅ File was save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "library_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
