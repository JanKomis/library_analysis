{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.path.abspath('')\n",
    "parent_dir = os.path.join(current_dir, '..', 'functions')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from duplicates_utils import normalize_id\n",
    "from mn_table_utils import create_mn_table\n",
    "from one_to_one_table_utils import create_one_to_one_table\n",
    "from duplicates_utils import number_of_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP DUPLICATES ROWS FROM AUTHORS AND CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(654021, 2)\n",
      "(653783, 2)\n",
      "654021\n"
     ]
    }
   ],
   "source": [
    "authors_path = \"../../dataset/cleaned/authors_cleaned.csv\"\n",
    "df_authors = pd.read_csv(authors_path)\n",
    "\n",
    "print(df_authors.shape)\n",
    "\n",
    "df_authors,df_authors_map = normalize_id(df_authors, key_column = 'author_name', id_column = 'author_id')\n",
    "\n",
    "print(df_authors.shape)\n",
    "print(len(df_authors_map))\n",
    "\n",
    "#Reduce the dictionary only to items where the key and value are different\n",
    "df_authors_map = {k: v for k, v in df_authors_map.items() if k != v}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2775, 2)\n",
      "(2585, 2)\n",
      "2775\n"
     ]
    }
   ],
   "source": [
    "categories_path = \"../../dataset/cleaned/categories_cleaned.csv\"\n",
    "df_categories = pd.read_csv(categories_path)\n",
    "\n",
    "\n",
    "print(df_categories.shape)\n",
    "\n",
    "df_categories,df_categories_map = normalize_id(df_categories, key_column = 'category_name', id_column = 'category_id')\n",
    "\n",
    "print(df_categories.shape)\n",
    "print(len(df_categories_map))\n",
    "\n",
    "#Reduce the dictionary only to items where the key and value are different\n",
    "df_categories_map = {k: v for k, v in df_categories_map.items() if k != v}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE M:N TABLES FROM MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../dataset/cleaned/dataset_cleaned.csv\"\n",
    "df_dataset = pd.read_csv(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTHOR MN TABLE\n",
    "authors_mn_table = create_mn_table(df_dataset, id_column = 'id', key_column = 'authors')\n",
    "\n",
    "#adds unknown id instead of missing id in mn table\n",
    "unknown_author_id = df_authors.loc[df_authors['author_name'] == 'Unknown', 'author_id'].iloc[0]\n",
    "\n",
    "#removes 'Unknown' author from df_authors dataset\n",
    "df_authors = df_authors.drop((df_authors[df_authors[\"author_id\"] \n",
    "                                         == unknown_author_id].index))\n",
    "\n",
    "\n",
    "authors_mn_table['authors_id'] = authors_mn_table['authors_id'].str.strip()\n",
    "authors_mn_table['authors_id'] = authors_mn_table['authors_id'].replace('', np.nan)\n",
    "authors_mn_table['authors_id'] = authors_mn_table['authors_id'].astype('Int64')\n",
    "\n",
    "authors_mn_table['authors_id'] = (authors_mn_table['authors_id'] \n",
    "    .replace(df_authors_map))\n",
    "\n",
    "#remove unknown_author_id author id\n",
    "authors_mn_table[\"authors_id\"] = (authors_mn_table[\"authors_id\"]\n",
    "                                  .replace(unknown_author_id, np.nan))\n",
    "\n",
    "authors_mn_table = authors_mn_table.dropna(subset=[\"authors_id\"])\n",
    "\n",
    "#drop duplicates\n",
    "authors_mn_table = authors_mn_table.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATHEGORIES MN TABLE\n",
    "categories_mn_table = create_mn_table(df_dataset, id_column = 'id', key_column = 'categories')\n",
    "\n",
    "categories_mn_table['categories_id'] = categories_mn_table['categories_id'].str.strip()\n",
    "categories_mn_table['categories_id'] = categories_mn_table['categories_id'].replace('', np.nan)\n",
    "categories_mn_table['categories_id'] = categories_mn_table['categories_id'].astype('Int64')\n",
    "\n",
    "categories_mn_table['categories_id'] = (categories_mn_table['categories_id'] \n",
    "    .replace(df_categories_map))\n",
    "\n",
    "#remove empty rows\n",
    "categories_mn_table = categories_mn_table.dropna(subset=[\"categories_id\"])\n",
    "\n",
    "#remove duplicates\n",
    "categories_mn_table = categories_mn_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE 1:1 TABLE FROM MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dataset, lang_mapping = create_one_to_one_table(df_dataset,'lang')\n",
    "\n",
    "df_dataset['lang'] = (df_dataset['lang']\n",
    "    .replace('', np.nan)  \n",
    "    .map(lang_mapping)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>tig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161</td>\n",
       "      <td>tai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>163</td>\n",
       "      <td>rm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id lang\n",
       "0      1   en\n",
       "1      2   es\n",
       "2      3  nan\n",
       "3      4   it\n",
       "4      5   de\n",
       "..   ...  ...\n",
       "158  159  art\n",
       "159  160  tig\n",
       "160  161  tai\n",
       "161  162   lg\n",
       "162  163   rm\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DROP OLD COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = df_dataset.drop(columns=['authors','categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT TO THE CORRECT COLUMN TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset[[\"format\", \"lang\"]] = df_dataset[\n",
    "                                [\"format\", \"lang\"]].astype(\"Int64\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RENAME COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_id</th>\n",
       "      <th>authors_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615318</th>\n",
       "      <td>1109380</td>\n",
       "      <td>336369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615319</th>\n",
       "      <td>1109381</td>\n",
       "      <td>29792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615320</th>\n",
       "      <td>1109381</td>\n",
       "      <td>654019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615321</th>\n",
       "      <td>1109382</td>\n",
       "      <td>654020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615322</th>\n",
       "      <td>1109383</td>\n",
       "      <td>654021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1597325 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         main_id  authors_id\n",
       "0              1           1\n",
       "1              2           2\n",
       "2              2           3\n",
       "3              3           4\n",
       "4              4           5\n",
       "...          ...         ...\n",
       "1615318  1109380      336369\n",
       "1615319  1109381       29792\n",
       "1615320  1109381      654019\n",
       "1615321  1109382      654020\n",
       "1615322  1109383      654021\n",
       "\n",
       "[1597325 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_mn_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = df_dataset.rename(columns=\n",
    "                               {'description': 'book_description',\n",
    "                                 'format': 'format_id',\n",
    "                                   'lang': 'language_id',\n",
    "                                   'id': 'book_id',\n",
    "                                   'publication-date': 'publication_date'})\n",
    "\n",
    "categories_mn_table = categories_mn_table.rename(columns=\n",
    "                                          {'main_id': 'book_id',\n",
    "                                           'categories_id':'category_id'})\n",
    "\n",
    "authors_mn_table = authors_mn_table.rename(columns=\n",
    "                                          {'main_id': 'book_id',\n",
    "                                            'authors_id':'author_id'})\n",
    "\n",
    "lang_dataset = lang_dataset.rename(columns=\n",
    "                                          {'id': 'language_id',\n",
    "                                            'lang':'language_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order_columns = ['book_id','title','book_description','isbn13',\n",
    "                     'publication_date', 'format_id', 'language_id']\n",
    "\n",
    "\n",
    "df_dataset = df_dataset[new_order_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_dataframes(df_dict, folder_path, file_format='csv'):\n",
    "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
    "        raise FileNotFoundError(f\"Dictionary '{folder_path}' does not exist.\")\n",
    "\n",
    "    for file_name, df in df_dict.items():\n",
    "        file_name = f\"{file_name}.{file_format}\" \n",
    "        file_path = os.path.join(folder_path, file_name)  \n",
    "\n",
    "        if file_format == 'csv':\n",
    "            df.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        elif file_format == 'xlsx':\n",
    "            df.to_excel(file_path, index=False, engine='openpyxl')\n",
    "        else:\n",
    "            raise ValueError(\"Unsuported file format.\")\n",
    "\n",
    "        print(f\"✅ File was save: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File was save: ../../dataset/to_sql\\final_dataset.csv\n",
      "✅ File was save: ../../dataset/to_sql\\final_categories.csv\n",
      "✅ File was save: ../../dataset/to_sql\\final_authors.csv\n",
      "✅ File was save: ../../dataset/to_sql\\mn_author.csv\n",
      "✅ File was save: ../../dataset/to_sql\\mn_categories.csv\n",
      "✅ File was save: ../../dataset/to_sql\\final_lang.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = {'final_dataset': df_dataset, 'final_categories': df_categories,\n",
    "       'final_authors': df_authors,'mn_author': authors_mn_table,\n",
    "       'mn_categories': categories_mn_table,'final_lang': lang_dataset}\n",
    "folder = \"../../dataset/to_sql\"\n",
    "\n",
    "save_dataframes(dfs, folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(file_names, source_folder, destination_folder):\n",
    "    for file_name in file_names:\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(source_path, \"rb\") as src, open(destination_path, \"wb\") as dst:\n",
    "                dst.write(src.read())\n",
    "            print(f\"✅ {file_name} was saved successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ File {file_name} not found in {source_folder}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ formats_cleaned.csv was saved successfully.\n",
      "✅ addition_cleaned.csv was saved successfully.\n"
     ]
    }
   ],
   "source": [
    "dt_without_trans = ['formats_cleaned.csv','addition_cleaned.csv']\n",
    "source_folder = \"../../dataset/cleaned\"\n",
    "final_path = \"../../dataset/to_sql\"\n",
    "move_files(dt_without_trans,source_folder,final_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "library_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
